{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lo9L8wu464J"
   },
   "source": [
    "#  ALZHEIMERS USING CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-30T10:54:33.855475Z",
     "iopub.status.busy": "2021-06-30T10:54:33.854982Z",
     "iopub.status.idle": "2021-06-30T10:54:40.861670Z",
     "shell.execute_reply": "2021-06-30T10:54:40.859965Z",
     "shell.execute_reply.started": "2021-06-30T10:54:33.855422Z"
    },
    "id": "Sa3h018A464K",
    "outputId": "9c46c3e7-d783-49b6-e1b6-5531fb40c593"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LSTM, Input, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import the backend\n",
    "from tensorflow.keras import backend as K\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Alzheimer_s Dataset/train/MildDemented/mildDem1.jpg\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 176, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnOWl_3R464M"
   },
   "source": [
    "# Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-06-30T10:54:48.808449Z",
     "iopub.status.busy": "2021-06-30T10:54:48.807710Z",
     "iopub.status.idle": "2021-06-30T10:54:55.146765Z",
     "shell.execute_reply": "2021-06-30T10:54:55.145149Z",
     "shell.execute_reply.started": "2021-06-30T10:54:48.808403Z"
    },
    "id": "thn7vKj0464N"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = [] \n",
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/train/MildDemented/\"):\n",
    "    label = \"MildDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/test/MildDemented/\"):\n",
    "    label = \"MildDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1IahbtCP464O"
   },
   "outputs": [],
   "source": [
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/train/VeryMildDemented/\"):\n",
    "    label = \"VeryMildDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/test/VeryMildDemented/\"):\n",
    "    label = \"VeryMildDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lYKdwTi1464O"
   },
   "outputs": [],
   "source": [
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/train/ModerateDemented/\"):\n",
    "    label = \"ModerateDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/test/ModerateDemented/\"):\n",
    "    label = \"ModerateDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t2bE8ayM464P"
   },
   "outputs": [],
   "source": [
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/train/NonDemented/\"):\n",
    "    label = \"NonDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "for dir_path in glob.glob(\"Alzheimer_s Dataset/test/NonDemented/\"):\n",
    "    label = \"NonDemented\"\n",
    "    for image_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (45, 45))\n",
    "        ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "        image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "        #image = cv2.Canny(image,100,200)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "03b8drTD464Q"
   },
   "outputs": [],
   "source": [
    "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
    "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZmeEu_b-464R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'MildDemented',\n",
       " 1: 'ModerateDemented',\n",
       " 2: 'NonDemented',\n",
       " 3: 'VeryMildDemented'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "26jiaXUV464R"
   },
   "outputs": [],
   "source": [
    "label_ids = np.array([label_to_id_dict[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2tZUY24t464R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 45, 45, 3), (6400,), (6400,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, label_ids.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYhLMh9V464S"
   },
   "source": [
    "# Prepare test (20%) and train (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2Y52-l7J464S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(images,label_ids, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L13e3PkA464S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gD8SVxyf464T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 3, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0PN3qQVV464T"
   },
   "outputs": [],
   "source": [
    "#Normalize color values to between 0 and 1\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "\n",
    "#Make a flattened version for some of our models\n",
    "X_flat_train = X_train.reshape(X_train.shape[0], 45*45*3)\n",
    "X_flat_test = X_test.reshape(X_test.shape[0], 45*45*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aSS8sp6F464T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 3, 3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sqDU8Pzj464U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sizes: (5120, 45, 45, 3) (1280, 45, 45, 3) (5120, 4) (1280, 4)\n",
      "Flattened: (5120, 6075) (1280, 6075)\n"
     ]
    }
   ],
   "source": [
    "#One Hot Encode the Output\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 4)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, 4)\n",
    "\n",
    "print('Original Sizes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('Flattened:', X_flat_train.shape, X_flat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kKQBLywS464U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbJElEQVR4nO2deZBU9bXHv0cW2VRkFRj2RUWjo4XK0xcqoikR98RHtOLyUhg1pRYGFUFxQSViNCRYUV8mosFUFJAlGnm+J0EoiqiorKLIpqDACCoMi0ZAOe+PvrxM33OGvnT3dPfM7/upmmJ+3/n17d+dnsPte/r8vkdUFYSQ+s9hxV4AIaQwMNgJCQQGOyGBwGAnJBAY7IQEAoOdkEDIKdhFZJCIrBKRtSIyMl+LIoTkH8n2c3YRaQBgNYAfAtgI4B0AV6rqBwd5DD/UJ6SWUVXx9Fyu7KcDWKuqH6nqXgCTAVySw/EIIbVILsHeCcCn1cYbI40QUoI0zOGx3lsF8zZdRK4HcH0Oz0MIyQO5BPtGAJ2rjcsAbI5PUtUKABUA79kJKSa5vI1/B0BvEekuIo0BXAHg5fwsixCSb7K+sqvqtyJyM4D/BdAAwDOq+n7eVkYIyStZf/SW1ZPxbTwhtU5tfPRGCKlDMNgJCQQGOyGBwGAnJBAY7IQEAoOdkEBgsBMSCAx2QgKBwU5IIDDYCQkEBjshgcBgJyQQGOyEBAKDnZBAYLATEgi52FJBRNYD2AXgOwDfqmq/fCyKEJJ/cgr2iLNV9Ys8HIfkmQcffNBojRs3Ntqdd96Z8ViPP/640U444QSj7dixw2iffPKJ0b788kujeesl+YNv4wkJhFyDXQG8JiKLIstoQkiJkuvb+LNUdbOItAMwW0Q+VNX51SfQN56Q0iCnK7uqbo7+3QpgJlItoeJzKlS1H5N3hBSXXBo7NgdwmKruir6fDeABVf2fgzyG7rLVGD16tNE6dOhgtPbt26eN9+3bl3EOAGzatMlolZWVRvvqq6+MNmbMmLTx2LFjzZxGjRoZbcSIEUZ75ZVXjHbhhRcabcaMGWnjtWvXmjleAtBbW8jU5C6by9v49gBmisiB4zx/sEAnhBSXXJpEfATg5DyuhRBSi/CjN0ICgcFOSCCw/VMRmTVrltH69OljtHhSqlmzZmZOlDtJ45tvvjHa119/bTQvEbZ+/fq0cffu3c2crl27Gm316tVG+/nPf260qVOnGu2jjz5KG7dt29bM+fTTT4120kknGe3II4802rnnnmu0+gjbPxESOAx2QgKBwU5IIDDYCQmEfGxxDZpRo0YZrVWrVkbzkll9+/Y12jvvvGO0Hj16pI33799v5jRo0MBoXiLP21rqVaXdd999aWNv+6lXQXfGGWcY7a233jLaq6++arT4ltlly5aZOf362aprr3rwzDPPNFro8MpOSCAw2AkJBAY7IYHAYCckEJigOwTGjRtntOOPP95oixYtMtqQIUOM5iWuTjvtNKPFqxy9qkcvmbV7926jtW7d2mjt2rUzWhyvIs3zlvOShyefbPdLXXPNNUaLV/d5FYDl5eVGmz9/vtE8nn76aaNt2LDBaPXVC49XdkICgcFOSCAw2AkJhIy73kTkGQAXAtiqqidGWisAUwB0A7AewBBV3Z7xyerYrrdHHnkkbezd7w4YMMBoXpHKhx9+aDRvB9dVV11ltPi97AcffGDmrFu3zmiHH3640Ro2tGmaNm3aGC2eY/CspVatWmU0b/dd8+bNjXb++ecb7bvvvksbe0U7hx1mr09eodDnn39utPiuOgC47rrrjPbcc8+ljb38QimTy663PwEYFNNGApijqr0BzInGhJASJmOwR9bQ22LyJQAmRd9PAnBpntdFCMkz2X701l5VKwFAVSsj33gX+sYTUhrU+ufsqloBoAKoe/fshNQnsg32LSLSIbqqdwCwNZ+LKhV27dqVNk7SABEA/v73vxtt4MCBRvOSWXv27DFaPKl27LHHmjm9evVKtDbvOdesWWO0X/3qV2ljr2jn22+/NZpnX+XZRk2ZMsVol16afjeYdNee57XvJR29wiDvvLxEXn0g24/eXgZwbfT9tQBeys9yCCG1RcZgF5EXALwJ4FgR2SgiQwGMA/BDEVkD4IfRmBBSwmR8G6+qV9bwo3PyvBZCSC3CCjpCAoG+8RFJmgP+85//NNpDDz1ktCeffNJo8eQT4CeMvMaL06dPTxt7O+0+++wzo91www1G84gfHwB+/OMfp429JpSe/ZZXLecl1e666y6jxXcLekk27/je7r7GjRsbraqqymhz5swx2i233JI2njBhQqJjxa28igV94wkJHAY7IYHAYCckEBjshAQCbaki7r777oxzvGTckiVLjOYlrrztplu32sJDL/ET3/rZsWNHM8fb+vnss88a7Wc/+5nRVqxYYbQ4nTt3NprXJNJLCs6ePTvj8QGbkPMsrrZti+/J8rfCesnUBQsWZHxOAHjjjTfSxl4iNYnXfqnBKzshgcBgJyQQGOyEBAKDnZBAqPcJunvvvddonv+ZV3EV93XfvHmzmTNt2jSjedVyRxxxhNG8ajlvu2Zc87zlH3vsMaPdfvvtRnv++eeNtmXLFqPF8ZKJ5513ntG8RKeXQPP89+Jbeb3Ku7Zt2xpt586dRvNez3jjSMDfjnzllTVtB/kXnrd80tegWPDKTkggMNgJCQQGOyGBkMS84hkR2SoiK6pp94vIJhFZGn0Nrt1lEkJyJUmTiAEAdgN4rlqTiPsB7FZVm5E4+LFKYotrvPkDAFxxxRVGi1e9eRVd8eo2wK9m8/zUPK8zLwEVf46VK1eaOd621xdffNFoXpNFL9GWhOXLlxtt+3bbK6RHjx5G8/7u4v54XtXexo0bjeZV8rVo0cJoXiPKuXPnGi2e3PNe4xEjRhitoqLCaNdfX3hj5ay3uNbgG08IqWPkcs9+s4gsj97mH13TJBG5XkTeFZF3c3guQkiOZBvsTwHoCaAcQCWA39Q0UVUrVLWfqvbL8rkIIXkgq2BX1S2q+p2q7gfwRwCn53dZhJB8k1UF3YEGEdHwMgCZ90iWEF6zh5YtWxotXnHlJd68zq5NmjQxmpfk8bZhdunSxWgff/xx2ri8vNzM2bt3r9F+8pOfGM1ripAtXhXcqaeeajSvmcQXX3yR8bFel9imTZsazTt37/fdtWtXo1188cVGi78u8+bNM3M8CunnmA0Zgz3yjf8BgDYishHAfQB+ICLlABSpls3JnA0JIUUjW9/4ibWwFkJILcIKOkICod77xscbFAK+Z/moUaOM9vDDD2c8vuc3f9111xnNu6/0fvfePXsc7x6yd+/eRvPub73CIG8d8cd6O8s8qy3v+Bs2bDBav36ZP5zxcgLffPON0Tzf+L/+9a9G89bbs2dPo8UbUXq5lTfffNNoN910k9GKAX3jCQkcBjshgcBgJyQQGOyEBEK9StB5VkHxZAvg+657RRhxKyavKMMrqvF+p3v27DGa50fuebgPHDjQaEnwdoh5eOuNJ7O89XtFRt76k+6qW79+fdr4qKOOMnPee+89ow0YMMBov/mNreD2dsfdc889GdflJWr79OljNC+heOutt2Y8fr5hgo6QwGGwExIIDHZCAoHBTkgg1KsEXVK8nV/Nmzc3WjwB5VVSebZGxx13nNG6detmtKS74+KJQs8O6vvf/77RvCSSxxNPPGG0eKXabbfdluhYkydPNlqnTp2M5iU241ZSXjXeV199ZbS4nRXgW36tXr3aaMOHDzdaPNHref57v2+vD4BnIXbHHXcYLZ8wQUdI4DDYCQkEBjshgZDEN76ziMwVkZUi8r6IDIv0ViIyW0TWRP/WaDpJCCk+SXzjOwDooKqLReQIAIsAXArgPwFsU9VxIjISwNGqav2e0o9V8ASdV0l1wQUXGG3Hjh1GW7RoUdrYazToJWqqqqqMtm/fPqN5iTwvGRR/jeKVZoCfPPS21W7atMloSbZmeluAv/e97xnNO0/vnLxqxFatWqWNvSTb/PnzjeZV2pWVlRnNq/jzqt5++ctfpo295qCnnHKK0S677DKjFYNcfOMrVXVx9P0uACsBdAJwCYBJ0bRJSP0HQAgpUQ7JcFJEugE4BcBCAO0PmE6qaqWItKvhMdcDKHxbDEJIGomDXURaAJgO4FZV3el9tumhqhUAKqJjlMTn7ISESKJsvIg0QirQ/6KqMyJ5S3Q/f+C+fmtNjyeEFJ8kCTpB6p58m6reWk1/FMCX1RJ0rVTVdrtLP1atXtn/8Ic/GC3epA/wk3HeVsSpU6emjRs2tG+EfvSjHyVam+dV520bveaaa4wWf428RKHnw+55s3kebuvWrTNavIrsueeey7guwN+2e/TR9oOadu3sXV88uecl1Lzk5+LFi402bNgwo3l+hF5i09sqXZeoKUGX5G38WQCuBvCeiCyNtLsAjAMwVUSGAvgEwH/kY6GEkNohiW/8AgA13aCfk9/lEEJqC1bQERIIDHZCAiGrxo6lyg03JGs5N27cOKN5Cai1a9emjb3mEknxEldnnHGG0bwEWtw7rUGDBmaO91Go95xehVubNm2MlmkNANC+fXujeWvzEqJe4jS+xdVrCNmoUSOjeefpkcvrVx/glZ2QQGCwExIIDHZCAqFe3bMnZeTIkXk7llfI89lnnxnNs2Hy7km9opFmzZqljb1iE+9YXhFQ/L4Y8HeXxfHuxb2iIM9qy7un9ubFn8OzCps5c6bRvDxHUjxP+Pg6vNfOy2F4r7tXTFUseGUnJBAY7IQEAoOdkEBgsBMSCPU+Qff4448bLe7DDgAPPfSQ0SZMmJA27tKli5njebjfd999Rhs9erTRjjnmGKN5Fk7xAhSvsKRt27ZG27Ztm9G8pF2vXr2MFsdL7HmJN69Yxvu9eQm/eFPIHj16mDne7+f22283mtewsW/fvkbr3LlzxueYPn26meMlDwvZgyEbeGUnJBAY7IQEAoOdkEDIxTf+fhHZJCJLo6/Btb9cQki25OIbPwTAblV9LPGTFcFwcuLEiUbzEmNeQ8WlS5emjT2f9F27dhnNs5byePXVV43mJbji1VonnniimeNVkXm2VF7l1yeffGK0eAPFG2+80cyZM2eO0bwmjl7Fn7eOuN1Wx44dzRxvB92SJUuM9otf/MJo48ePN5rXQ2Dz5s1p47PPPtvMKWWytqWK7KIPWEbvEpEDvvGEkDrEId2zx3zjAeBmEVkuIs+w/RMhpU3iYI/7xgN4CkBPAOVIXfltn6XU464XkXdF5N08rJcQkiVZ+8ar6hZV/U5V9wP4I4DTvceqaoWq9lPVfvlaNCHk0Ml4zx75xk8EsFJVx1fTOxxo/wTgMgArvMcXm6FDhyaa53mFx5v3ef7nXjM/rxFgv372/zqvAs1Lqu3fvz9tvH37djPHa27YsmVLo5122mlG81i4cGHGOeecY82Fve2yXrXczp07Mx7f83Tv379/xsfVhLcld9WqVUaLN9ycMWOGmeM11xw+fHjWaysEufjGXyki5QAUwHoAyQzgCCFFIRff+P/O/3IIIbUFK+gICQQGOyGBUO+3uHq8/fbbRotXjAFAq1at0sbedlZva6y3ndXj6aefNtpJJ51ktLi3mZfE69Chg9HefTf7Tzs9T/s48S3AgP878ir+PK/6TZs2pY29BKPHlClTjOZtj/W2pb711ltGmz17dsZ1eFWYpQ6v7IQEAoOdkEBgsBMSCAx2QgIhyATd6ae7lb2GuXPnpo29RFO8yg7wq9QWLFhgtHhCCvCr0uIVc127djVzVq5caTSvSi2XhGKmdQFA06ZNjVZZWWm0srIyo51wwglp43nz5iVah1fNdvLJJxvN2z7sNdeIV+7ddNNNidZR6vDKTkggMNgJCQQGOyGBkNGWKq9PVgRbqtrmtddeM5rnTz5r1iyj3XCD3TvkFfy0a9cubbxv3z4z54033jCaZ5l18803Gy2feIU23m7B888/32jxwqZu3bqZOb/+9a+N5hUAeTZd7du3N5p3H//5558fdAwAl19+udFKhZpsqXhlJyQQGOyEBAKDnZBASOIb30RE3haRZZFv/JhI7y4iC0VkjYhMERF780MIKRmS+MYLgOaqujvyolsAYBiA4QBmqOpkEfkvAMtU9akMxyqJBJ3X7NGziGrWrFna+NhjjzVzvIIRr4DGK2bx8DzQ47vvVq9ebeZ49kq5JON+//vf5+1Yzz//vNE8L/Z4McvkyZPNnLvuustoY8eONdrhhx9uNK8BZH0k6wSdpjiwp7JR9KUABgKYFumTkGocQQgpUZK6yzaI/Oe2ApgNYB2AKlU9UGu4EWwcQUhJkyjYI8vocgBlSFlGH+9N8x5L33hCSoNDysarahWAeQD6A2gpIgc20pQB2FzDY+gbT0gJkCRB1xbAPlWtEpGmAF4D8AiAawFMr5agW66qT2Y4Vkkk6Dxef/11o8Ur11q0aGHmxC2jatI+/PBDo3n2Up4PfevWrdPGe/fuNXP69OljNI+NGzcazbOIilezec0ZPR92z65p3LhxRrv66quNFm+u2aVLFzPH46mnbF540KBBRvMqD5PsevOqE2+55ZZEaysGWTd2BNABwCQRaYDUO4GpqvqKiHwAYLKIPARgCVKNJAghJUoS3/jlSDVzjOsfoYaWT4SQ0oMVdIQEAoOdkEDgFteIJ554wmjxhI6XyCovLzeat22yYUN7x+RV38Wr5QBr9eQ1SvR87zt27Gg0j6+//tpo8SSgZzfVpEmTROuIJ94Af/ttvIrRa+y4detWo3lJQW8dXjLOSzIm8cwvZbjFlZDAYbATEggMdkICgcFOSCAwQXcQ4lsnPQ+zM88802jedlkvSeVp3tbMOF4C0HsdvYqxL7/80mjTpk0z2gMPPJA2jm95BfwEoOfX7v0+vORbPOHn+d57bNu2zWheReTIkSMTHW/8+PFp4+HDhyd6XKnABB0hgcNgJyQQGOyEBAKDnZBAYILuEJg40W7s6969u9EWL15sNK9RwoABA4zmVarFk3aNGjUyc6qqqozmJa68pJe3hdPzekuC14yxZ8+eiR4bTyh6yUqv+YOXYLzzzjsTPWd9hAk6QgKHwU5IIOTiG/8nEflYRJZGX3ZHCCGkZEjiVLMHwMDqvvEi8mr0sztU1d4wEUJKjiRONQrA840PDs8Tbfbs2UZ7+OGHE81LmhyNJ6W86jOv42k+8XzkBg8ebLQNGzYYzWt8ceqppxotXkE3c+ZMM+ess85KtI5evXoZzfMBvPvuu41WX8nKN15VF0Y/Gisiy0XktyKSuc6TEFI0svKNF5ETAYwCcByA0wC0AuB+1kHfeEJKg2x94wepamXUGmoPgGdRg/kkfeMJKQ0y3rM7vvHnAnhERDqoamXU+PFSACtqea1Fx2vY6N2f33PPPUbzLK08r/dly5YZ7aijjkobH3HEEWbO3/72N6NddNFFRssWb8dY0l1k//jHP4zm2UG9//77aWPPf9+zAZs1a5bRli5darQHH3zwoOus7+TiG/969B+BAFgK4MZaXCchJEdy8Y0fWCsrIoTUCqygIyQQGOyEBEKSe3YSMWbMGKM9+uijRjvlFHPX42oTJkwwmtdAMe457yW3PDuoP//5z0bbsWOH0Twv9rgtlccLL7xgtP79+xvNs9Havn270eJFNd4OQI9NmzYZLfRknAev7IQEAoOdkEBgsBMSCAx2QgKBCbocueOOO7J+rOdD71XHpYoU/4XnN+81Lbz66quzXlscr1LQq3BL2tjRI76bL6k11pYtWxLNCx1e2QkJBAY7IYHAYCckEBjshAQCfeOLyOjRo43m2UvF7bDmzp1r5jRr1sxozZs3N1o+mxS+9NJLRtu7d6/RvL+xIUOG5G0dJB36xhMSOAx2QgIhcbBHppNLROSVaNxdRBaKyBoRmSIidrcDIaRkOJQr+zAAK6uNHwHwW1XtDWA7gKH5XBghJL8kStCJSBmASQDGAhgO4CIAnwM4RlW/FZF/A3C/qp6X4ThM0BWQl19+2WirVq0yWrZVgJ7XXosWLYwWcpPFYpBrgu53AEYA2B+NWwOoUtUDNZobAXTKaYWEkFolSa+3CwFsVdVF1WVnqnvVpm88IaVBko0wZwG4WEQGA2gC4EikrvQtRaRhdHUvA7DZe7CqVgCoAPg2npBikvHKrqqjVLVMVbsBuALA66r6UwBzAVweTbsWgK2wIISUDIdUQSciPwBwu6peKCI9AExGqvXTEgBXRd1hDvZ4XtkJqWVqStCxXJaQegbLZQkJHAY7IYHAYCckEBjshAQCg52QQGCwExIIDHZCAoHBTkggMNgJCQQGOyGBwGAnJBAY7IQEAoOdkEBgsBMSCAx2QgKBwU5IIDDYCQmEJIaT+eQLABsAtIm+r8vU9XPg+otPbZxD15p+UFBbqv9/UpF3VbVfwZ84j9T1c+D6i0+hz4Fv4wkJBAY7IYFQrGCvKNLz5pO6fg5cf/Ep6DkU5Z6dEFJ4+DaekEAoeLCLyCARWSUia0VkZKGf/1ARkWdEZKuIrKimtRKR2SKyJvr36GKu8WCISGcRmSsiK0XkfREZFul16RyaiMjbIrIsOocxkd5dRBZG5zBFRBoXe60HQ0QaiMgSEXklGhd0/QUNdhFpAOAJAOcD6AvgShHpW8g1ZMGfAAyKaSMBzFHV3gDmRONS5VsAt6nq8QD6A7gp+p3XpXPYA2Cgqp4MoBzAIBHpD+ARAL+NzmE7gKFFXGMShgFYWW1c0PUX+sp+OoC1qvqRqu5FqlfcJQVewyGhqvMBbIvJlwCYFH0/CcClBV3UIaCqlaq6OPp+F1J/bJ1Qt85BVXV3NGwUfSmAgQCmRXpJn4OIlAG4AMDT0VhQ4PUXOtg7Afi02nhjpNU12qtqJZAKJgDtiryeRIhINwCnAFiIOnYO0VvgpQC2ApgNYB2AqqhlOFD6f0u/AzACwP5o3BoFXn+hg91rOMePAwqAiLQAMB3Araq6s9jrOVRU9TtVLQdQhtQ7xOO9aYVdVTJE5EIAW1V1UXXZmVqr6y90bfxGAJ2rjcsAbC7wGvLBFhHpoKqVItIBqatNySIijZAK9L+o6oxIrlPncABVrRKReUjlH1qKSMPo6ljKf0tnAbhYRAYDaALgSKSu9AVdf6Gv7O8A6B1lIRsDuALAywVeQz54GcC10ffXAnipiGs5KNG94UQAK1V1fLUf1aVzaCsiLaPvmwI4F6ncw1wAl0fTSvYcVHWUqpapajek/uZfV9WfotDrV9WCfgEYDGA1Uvdcdxf6+bNY7wsAKgHsQ+qdyVCk7rfmAFgT/duq2Os8yPr/Ham3h8sBLI2+BtexczgJwJLoHFYAuDfSewB4G8BaAC8COLzYa01wLj8A8Eox1s8KOkICgRV0hAQCg52QQGCwExIIDHZCAoHBTkggMNgJCQQGOyGBwGAnJBD+Dw2+Cp6aooBIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data.shape[1])\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q82NEW2P464V"
   },
   "source": [
    "# CNN (convolutional Neural Network) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "QywLbZJn464V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "5120/5120 [==============================] - 37s 7ms/sample - loss: 1.4247 - acc: 0.2207 - val_loss: 1.3217 - val_acc: 0.4492\n",
      "Test loss: 1.3217419773340224\n",
      "Test accuracy: 0.44921875\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "# First convolutional layer, note the specification of shape\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(45, 45, 3)))\n",
    "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_cnn.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_cnn.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5WFEKYpq464V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 40s 8ms/sample - loss: 1.2807 - acc: 0.4275 - val_loss: 1.2010 - val_acc: 0.4984\n",
      "Epoch 2/10\n",
      "5120/5120 [==============================] - 44s 9ms/sample - loss: 1.1896 - acc: 0.4799 - val_loss: 1.1293 - val_acc: 0.4984\n",
      "Epoch 3/10\n",
      "5120/5120 [==============================] - 45s 9ms/sample - loss: 1.1314 - acc: 0.4912 - val_loss: 1.0884 - val_acc: 0.4984\n",
      "Epoch 4/10\n",
      "5120/5120 [==============================] - 49s 10ms/sample - loss: 1.1040 - acc: 0.4922 - val_loss: 1.0670 - val_acc: 0.4984\n",
      "Epoch 5/10\n",
      "5120/5120 [==============================] - 40s 8ms/sample - loss: 1.0847 - acc: 0.4930 - val_loss: 1.0538 - val_acc: 0.4984\n",
      "Epoch 6/10\n",
      "5120/5120 [==============================] - 47s 9ms/sample - loss: 1.0783 - acc: 0.4908 - val_loss: 1.0456 - val_acc: 0.4984\n",
      "Epoch 7/10\n",
      "5120/5120 [==============================] - 50s 10ms/sample - loss: 1.0740 - acc: 0.4889 - val_loss: 1.0394 - val_acc: 0.4984\n",
      "Epoch 8/10\n",
      "5120/5120 [==============================] - 46s 9ms/sample - loss: 1.0649 - acc: 0.4889 - val_loss: 1.0346 - val_acc: 0.4984\n",
      "Epoch 9/10\n",
      "5120/5120 [==============================] - 37s 7ms/sample - loss: 1.0655 - acc: 0.4848 - val_loss: 1.0310 - val_acc: 0.4984\n",
      "Epoch 10/10\n",
      "5120/5120 [==============================] - 44s 9ms/sample - loss: 1.0560 - acc: 0.4959 - val_loss: 1.0277 - val_acc: 0.4984\n",
      "Test loss: 1.0277272403240203\n",
      "Test accuracy: 0.4984375\n"
     ]
    }
   ],
   "source": [
    "model_cnn.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_XezW2B464W"
   },
   "source": [
    "# Multi layer neural network with two dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ux0t5kpH464W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               777728    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 786,244\n",
      "Trainable params: 786,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 2s 294us/sample - loss: 1.5696 - acc: 0.4686 - val_loss: 0.9837 - val_acc: 0.4984\n",
      "Epoch 2/10\n",
      "5120/5120 [==============================] - 1s 238us/sample - loss: 1.0121 - acc: 0.5063 - val_loss: 0.9954 - val_acc: 0.4828\n",
      "Epoch 3/10\n",
      "5120/5120 [==============================] - 1s 274us/sample - loss: 0.9666 - acc: 0.5420 - val_loss: 0.9689 - val_acc: 0.5805\n",
      "Epoch 4/10\n",
      "5120/5120 [==============================] - 1s 286us/sample - loss: 0.9142 - acc: 0.5709 - val_loss: 0.9525 - val_acc: 0.5258\n",
      "Epoch 5/10\n",
      "5120/5120 [==============================] - 1s 246us/sample - loss: 0.9023 - acc: 0.5754 - val_loss: 0.8285 - val_acc: 0.6180\n",
      "Epoch 6/10\n",
      "5120/5120 [==============================] - 1s 246us/sample - loss: 0.8602 - acc: 0.5980 - val_loss: 0.8453 - val_acc: 0.6172\n",
      "Epoch 7/10\n",
      "5120/5120 [==============================] - 1s 279us/sample - loss: 0.8106 - acc: 0.6246 - val_loss: 0.7814 - val_acc: 0.63050s - loss: 0.8116 - acc:\n",
      "Epoch 8/10\n",
      "5120/5120 [==============================] - 2s 295us/sample - loss: 0.7753 - acc: 0.6504 - val_loss: 0.9974 - val_acc: 0.5461\n",
      "Epoch 9/10\n",
      "5120/5120 [==============================] - 2s 313us/sample - loss: 0.7517 - acc: 0.6701 - val_loss: 0.7828 - val_acc: 0.6430\n",
      "Epoch 10/10\n",
      "5120/5120 [==============================] - 2s 296us/sample - loss: 0.7092 - acc: 0.6820 - val_loss: 0.7726 - val_acc: 0.6430\n",
      "Test loss: 0.7726089850068092\n",
      "Test accuracy: 0.6429688\n"
     ]
    }
   ],
   "source": [
    "model_dense=Sequential()\n",
    "# Add dense layers to create a fully connected MLP\n",
    "# Note that we specify an input shape for the first layer, but only the first layer.\n",
    "# Relu is the activation function used\n",
    "model_dense.add(Dense(128, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "# Dropout layers remove features and fight overfitting\n",
    "model_dense.add(Dropout(0.1))\n",
    "model_dense.add(Dense(64, activation='relu'))\n",
    "model_dense.add(Dropout(0.1))\n",
    "# End with a number of units equal to the number of classes we have for our outcome\n",
    "model_dense.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_dense.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_dense = model_dense.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_dense.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBBvlEp7464X"
   },
   "source": [
    "# Multi layer neural network with five hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UVsEYXYL464Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,638,404\n",
      "Trainable params: 1,638,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 3s 576us/sample - loss: 1.1321 - acc: 0.4646 - val_loss: 1.0517 - val_acc: 0.4984\n",
      "Epoch 2/10\n",
      "5120/5120 [==============================] - 2s 456us/sample - loss: 1.0073 - acc: 0.4977 - val_loss: 0.9948 - val_acc: 0.5570\n",
      "Epoch 3/10\n",
      "5120/5120 [==============================] - 2s 451us/sample - loss: 0.9605 - acc: 0.5332 - val_loss: 0.8820 - val_acc: 0.5680\n",
      "Epoch 4/10\n",
      "5120/5120 [==============================] - 2s 452us/sample - loss: 0.9264 - acc: 0.5562 - val_loss: 0.9038 - val_acc: 0.5484\n",
      "Epoch 5/10\n",
      "5120/5120 [==============================] - 2s 456us/sample - loss: 0.9021 - acc: 0.5590 - val_loss: 0.8130 - val_acc: 0.6109\n",
      "Epoch 6/10\n",
      "5120/5120 [==============================] - 2s 456us/sample - loss: 0.8814 - acc: 0.5678 - val_loss: 0.8230 - val_acc: 0.5469\n",
      "Epoch 7/10\n",
      "5120/5120 [==============================] - 2s 462us/sample - loss: 0.8417 - acc: 0.5955 - val_loss: 0.7961 - val_acc: 0.6102\n",
      "Epoch 8/10\n",
      "5120/5120 [==============================] - 2s 470us/sample - loss: 0.8131 - acc: 0.6133 - val_loss: 0.9186 - val_acc: 0.5281\n",
      "Epoch 9/10\n",
      "5120/5120 [==============================] - 2s 470us/sample - loss: 0.7815 - acc: 0.6271 - val_loss: 0.6950 - val_acc: 0.6898\n",
      "Epoch 10/10\n",
      "5120/5120 [==============================] - 2s 455us/sample - loss: 0.7384 - acc: 0.6551 - val_loss: 0.6705 - val_acc: 0.6719\n",
      "Test loss: 0.6705410480499268\n",
      "Test accuracy: 0.671875\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "\n",
    "# Add dense layers to create a fully connected MLP\n",
    "# Note that we specify an input shape for the first layer, but only the first layer.\n",
    "# Relu is the activation function used\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "# Dropout layers remove features and fight overfitting\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "# End with a number of units equal to the number of classes we have for our outcome\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxjLDt1U464Y"
   },
   "source": [
    "# Multi layer neural network with five hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               3110912   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 3,325,188\n",
      "Trainable params: 3,325,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 4s 688us/sample - loss: 1.1760 - acc: 0.4807 - val_loss: 0.9949 - val_acc: 0.4984\n",
      "Epoch 2/10\n",
      "5120/5120 [==============================] - 3s 578us/sample - loss: 1.0188 - acc: 0.4973 - val_loss: 0.9429 - val_acc: 0.5008\n",
      "Epoch 3/10\n",
      "5120/5120 [==============================] - 3s 606us/sample - loss: 0.9853 - acc: 0.5094 - val_loss: 0.9931 - val_acc: 0.5070\n",
      "Epoch 4/10\n",
      "5120/5120 [==============================] - 3s 610us/sample - loss: 0.9418 - acc: 0.5336 - val_loss: 0.8823 - val_acc: 0.5719\n",
      "Epoch 5/10\n",
      "5120/5120 [==============================] - 3s 629us/sample - loss: 0.9218 - acc: 0.5445 - val_loss: 0.8521 - val_acc: 0.5742\n",
      "Epoch 6/10\n",
      "5120/5120 [==============================] - 3s 623us/sample - loss: 0.8836 - acc: 0.5604 - val_loss: 0.8283 - val_acc: 0.5938\n",
      "Epoch 7/10\n",
      "5120/5120 [==============================] - 3s 630us/sample - loss: 0.8364 - acc: 0.6104 - val_loss: 0.9337 - val_acc: 0.5961\n",
      "Epoch 8/10\n",
      "5120/5120 [==============================] - 3s 641us/sample - loss: 0.8480 - acc: 0.5896 - val_loss: 0.7849 - val_acc: 0.6156\n",
      "Epoch 9/10\n",
      "5120/5120 [==============================] - 3s 658us/sample - loss: 0.7939 - acc: 0.6236 - val_loss: 0.7954 - val_acc: 0.5984\n",
      "Epoch 10/10\n",
      "5120/5120 [==============================] - 3s 645us/sample - loss: 0.7629 - acc: 0.6375 - val_loss: 0.7536 - val_acc: 0.6102\n",
      "Test loss: 0.7535771027207374\n",
      "Test accuracy: 0.61015624\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "model_deep.add(Dense(512, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(256, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,646,404\n",
      "Trainable params: 1,646,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 2s 401us/sample - loss: 1.0947 - acc: 0.4549 - val_loss: 0.9954 - val_acc: 0.4984\n",
      "Epoch 2/10\n",
      "5120/5120 [==============================] - 2s 334us/sample - loss: 1.0162 - acc: 0.4955 - val_loss: 0.9504 - val_acc: 0.5031\n",
      "Epoch 3/10\n",
      "5120/5120 [==============================] - 2s 353us/sample - loss: 0.9710 - acc: 0.5273 - val_loss: 0.9075 - val_acc: 0.5680\n",
      "Epoch 4/10\n",
      "5120/5120 [==============================] - 2s 359us/sample - loss: 0.9362 - acc: 0.5377 - val_loss: 0.8887 - val_acc: 0.5203\n",
      "Epoch 5/10\n",
      "5120/5120 [==============================] - 2s 361us/sample - loss: 0.8999 - acc: 0.5648 - val_loss: 0.8735 - val_acc: 0.5758\n",
      "Epoch 6/10\n",
      "5120/5120 [==============================] - 2s 381us/sample - loss: 0.8814 - acc: 0.5709 - val_loss: 0.8300 - val_acc: 0.6141\n",
      "Epoch 7/10\n",
      "5120/5120 [==============================] - 2s 376us/sample - loss: 0.8430 - acc: 0.5861 - val_loss: 0.8848 - val_acc: 0.5523\n",
      "Epoch 8/10\n",
      "5120/5120 [==============================] - 2s 395us/sample - loss: 0.8275 - acc: 0.6051 - val_loss: 0.8881 - val_acc: 0.5836\n",
      "Epoch 9/10\n",
      "5120/5120 [==============================] - 3s 518us/sample - loss: 0.7735 - acc: 0.6449 - val_loss: 0.7632 - val_acc: 0.6047\n",
      "Epoch 10/10\n",
      "5120/5120 [==============================] - 2s 395us/sample - loss: 0.7768 - acc: 0.6230 - val_loss: 0.7636 - val_acc: 0.6414\n",
      "Test loss: 0.7636444374918938\n",
      "Test accuracy: 0.64140624\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_83 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,650,564\n",
      "Trainable params: 1,650,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/28\n",
      "5120/5120 [==============================] - 3s 615us/sample - loss: 1.1172 - acc: 0.4719 - val_loss: 1.0095 - val_acc: 0.4992\n",
      "Epoch 2/28\n",
      "5120/5120 [==============================] - 2s 357us/sample - loss: 1.0143 - acc: 0.5164 - val_loss: 1.0002 - val_acc: 0.5586\n",
      "Epoch 3/28\n",
      "5120/5120 [==============================] - 2s 378us/sample - loss: 0.9594 - acc: 0.5363 - val_loss: 0.9721 - val_acc: 0.5156\n",
      "Epoch 4/28\n",
      "5120/5120 [==============================] - 2s 407us/sample - loss: 0.9304 - acc: 0.5420 - val_loss: 1.0518 - val_acc: 0.3969\n",
      "Epoch 5/28\n",
      "5120/5120 [==============================] - 2s 395us/sample - loss: 0.9211 - acc: 0.5449 - val_loss: 1.1246 - val_acc: 0.5102\n",
      "Epoch 6/28\n",
      "5120/5120 [==============================] - 2s 396us/sample - loss: 0.8641 - acc: 0.5920 - val_loss: 1.0224 - val_acc: 0.5445\n",
      "Epoch 7/28\n",
      "5120/5120 [==============================] - 2s 418us/sample - loss: 0.8387 - acc: 0.6016 - val_loss: 0.7792 - val_acc: 0.6461\n",
      "Epoch 8/28\n",
      "5120/5120 [==============================] - 2s 411us/sample - loss: 0.8375 - acc: 0.6170 - val_loss: 0.7995 - val_acc: 0.6203\n",
      "Epoch 9/28\n",
      "5120/5120 [==============================] - 2s 407us/sample - loss: 0.8006 - acc: 0.6193 - val_loss: 0.7416 - val_acc: 0.6570\n",
      "Epoch 10/28\n",
      "5120/5120 [==============================] - 2s 417us/sample - loss: 0.7856 - acc: 0.6453 - val_loss: 0.7626 - val_acc: 0.6258\n",
      "Epoch 11/28\n",
      "5120/5120 [==============================] - 2s 419us/sample - loss: 0.7353 - acc: 0.6605 - val_loss: 0.8385 - val_acc: 0.5750\n",
      "Epoch 12/28\n",
      "5120/5120 [==============================] - 2s 404us/sample - loss: 0.7211 - acc: 0.6713 - val_loss: 1.6008 - val_acc: 0.5570\n",
      "Epoch 13/28\n",
      "5120/5120 [==============================] - 2s 415us/sample - loss: 0.7135 - acc: 0.6947 - val_loss: 0.6638 - val_acc: 0.6945\n",
      "Epoch 14/28\n",
      "5120/5120 [==============================] - 2s 417us/sample - loss: 0.6366 - acc: 0.7170 - val_loss: 0.6495 - val_acc: 0.7148\n",
      "Epoch 15/28\n",
      "5120/5120 [==============================] - 2s 418us/sample - loss: 0.6577 - acc: 0.7250 - val_loss: 0.6445 - val_acc: 0.6828\n",
      "Epoch 16/28\n",
      "5120/5120 [==============================] - 2s 431us/sample - loss: 0.6236 - acc: 0.7498 - val_loss: 0.5974 - val_acc: 0.7711\n",
      "Epoch 17/28\n",
      "5120/5120 [==============================] - 2s 476us/sample - loss: 0.6010 - acc: 0.7650 - val_loss: 0.6158 - val_acc: 0.7422\n",
      "Epoch 18/28\n",
      "5120/5120 [==============================] - 2s 468us/sample - loss: 0.5873 - acc: 0.7713 - val_loss: 1.0804 - val_acc: 0.6070\n",
      "Epoch 19/28\n",
      "5120/5120 [==============================] - 2s 435us/sample - loss: 0.5110 - acc: 0.7973 - val_loss: 0.5020 - val_acc: 0.7937\n",
      "Epoch 20/28\n",
      "5120/5120 [==============================] - 3s 498us/sample - loss: 0.4884 - acc: 0.8021 - val_loss: 0.7411 - val_acc: 0.7164\n",
      "Epoch 21/28\n",
      "5120/5120 [==============================] - 2s 432us/sample - loss: 0.4962 - acc: 0.8084 - val_loss: 0.5817 - val_acc: 0.7820\n",
      "Epoch 22/28\n",
      "5120/5120 [==============================] - 2s 435us/sample - loss: 0.4502 - acc: 0.8295 - val_loss: 0.5996 - val_acc: 0.7328\n",
      "Epoch 23/28\n",
      "5120/5120 [==============================] - 2s 425us/sample - loss: 0.4616 - acc: 0.8334 - val_loss: 0.6920 - val_acc: 0.7391\n",
      "Epoch 24/28\n",
      "5120/5120 [==============================] - 2s 409us/sample - loss: 0.3948 - acc: 0.8512 - val_loss: 0.4983 - val_acc: 0.8195\n",
      "Epoch 25/28\n",
      "5120/5120 [==============================] - 2s 406us/sample - loss: 0.4124 - acc: 0.8434 - val_loss: 0.7236 - val_acc: 0.7063\n",
      "Epoch 26/28\n",
      "5120/5120 [==============================] - 2s 423us/sample - loss: 0.4112 - acc: 0.8617 - val_loss: 2.2741 - val_acc: 0.4781\n",
      "Epoch 27/28\n",
      "5120/5120 [==============================] - 2s 414us/sample - loss: 0.4131 - acc: 0.8594 - val_loss: 0.3530 - val_acc: 0.8687\n",
      "Epoch 28/28\n",
      "5120/5120 [==============================] - 2s 442us/sample - loss: 0.3546 - acc: 0.8895 - val_loss: 0.2904 - val_acc: 0.8984\n",
      "Test loss: 0.29035250749439\n",
      "Test accuracy: 0.8984375\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=28,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/15\n",
      "5120/5120 [==============================] - 3s 564us/sample - loss: 1.0782 - acc: 0.4705 - val_loss: 1.0089 - val_acc: 0.5266\n",
      "Epoch 2/15\n",
      "5120/5120 [==============================] - 2s 396us/sample - loss: 1.0048 - acc: 0.5049 - val_loss: 0.9921 - val_acc: 0.5500\n",
      "Epoch 3/15\n",
      "5120/5120 [==============================] - 2s 425us/sample - loss: 0.9600 - acc: 0.5334 - val_loss: 0.9815 - val_acc: 0.5211\n",
      "Epoch 4/15\n",
      "5120/5120 [==============================] - 2s 403us/sample - loss: 0.9244 - acc: 0.5516 - val_loss: 0.8947 - val_acc: 0.5625\n",
      "Epoch 5/15\n",
      "5120/5120 [==============================] - 2s 433us/sample - loss: 0.8892 - acc: 0.5703 - val_loss: 0.9508 - val_acc: 0.5312\n",
      "Epoch 6/15\n",
      "5120/5120 [==============================] - 2s 426us/sample - loss: 0.8733 - acc: 0.5781 - val_loss: 0.7936 - val_acc: 0.6172\n",
      "Epoch 7/15\n",
      "5120/5120 [==============================] - 2s 437us/sample - loss: 0.8611 - acc: 0.5727 - val_loss: 0.8176 - val_acc: 0.6094\n",
      "Epoch 8/15\n",
      "5120/5120 [==============================] - 2s 450us/sample - loss: 0.8357 - acc: 0.5998 - val_loss: 0.7805 - val_acc: 0.6367\n",
      "Epoch 9/15\n",
      "5120/5120 [==============================] - 2s 416us/sample - loss: 0.7959 - acc: 0.6139 - val_loss: 0.8971 - val_acc: 0.5383\n",
      "Epoch 10/15\n",
      "5120/5120 [==============================] - 2s 435us/sample - loss: 0.7803 - acc: 0.6379 - val_loss: 0.7610 - val_acc: 0.6391\n",
      "Epoch 11/15\n",
      "5120/5120 [==============================] - 2s 426us/sample - loss: 0.7674 - acc: 0.6463 - val_loss: 1.2536 - val_acc: 0.3664\n",
      "Epoch 12/15\n",
      "5120/5120 [==============================] - 2s 414us/sample - loss: 0.7422 - acc: 0.6637 - val_loss: 0.7158 - val_acc: 0.6875\n",
      "Epoch 13/15\n",
      "5120/5120 [==============================] - 2s 414us/sample - loss: 0.7173 - acc: 0.6752 - val_loss: 0.7384 - val_acc: 0.6758\n",
      "Epoch 14/15\n",
      "5120/5120 [==============================] - 2s 438us/sample - loss: 0.6571 - acc: 0.7068 - val_loss: 0.9019 - val_acc: 0.6805\n",
      "Epoch 15/15\n",
      "5120/5120 [==============================] - 2s 409us/sample - loss: 0.6529 - acc: 0.7240 - val_loss: 0.6361 - val_acc: 0.7023\n",
      "Test loss: 0.6361197128891944\n",
      "Test accuracy: 0.70234376\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=15,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,652,516\n",
      "Trainable params: 1,652,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/15\n",
      "5120/5120 [==============================] - 3s 583us/sample - loss: 1.0975 - acc: 0.4695 - val_loss: 1.0715 - val_acc: 0.5063\n",
      "Epoch 2/15\n",
      "5120/5120 [==============================] - 2s 415us/sample - loss: 1.0198 - acc: 0.4939 - val_loss: 1.0019 - val_acc: 0.4992\n",
      "Epoch 3/15\n",
      "5120/5120 [==============================] - 2s 438us/sample - loss: 0.9954 - acc: 0.5000 - val_loss: 0.9472 - val_acc: 0.5219\n",
      "Epoch 4/15\n",
      "5120/5120 [==============================] - 2s 429us/sample - loss: 0.9489 - acc: 0.5346 - val_loss: 0.8799 - val_acc: 0.5609\n",
      "Epoch 5/15\n",
      "5120/5120 [==============================] - 2s 425us/sample - loss: 0.9059 - acc: 0.5437 - val_loss: 0.9823 - val_acc: 0.5312\n",
      "Epoch 6/15\n",
      "5120/5120 [==============================] - 2s 451us/sample - loss: 0.8921 - acc: 0.5549 - val_loss: 0.8606 - val_acc: 0.5852\n",
      "Epoch 7/15\n",
      "5120/5120 [==============================] - 2s 427us/sample - loss: 0.8587 - acc: 0.5871 - val_loss: 0.7776 - val_acc: 0.6359\n",
      "Epoch 8/15\n",
      "5120/5120 [==============================] - 2s 469us/sample - loss: 0.8366 - acc: 0.6090 - val_loss: 0.7801 - val_acc: 0.6109\n",
      "Epoch 9/15\n",
      "5120/5120 [==============================] - 2s 437us/sample - loss: 0.8121 - acc: 0.6314 - val_loss: 0.7896 - val_acc: 0.6187\n",
      "Epoch 10/15\n",
      "5120/5120 [==============================] - 2s 420us/sample - loss: 0.8237 - acc: 0.6334 - val_loss: 0.7465 - val_acc: 0.6625\n",
      "Epoch 11/15\n",
      "5120/5120 [==============================] - 2s 423us/sample - loss: 0.7580 - acc: 0.6619 - val_loss: 1.1823 - val_acc: 0.5234\n",
      "Epoch 12/15\n",
      "5120/5120 [==============================] - 2s 445us/sample - loss: 0.7338 - acc: 0.6684 - val_loss: 0.7982 - val_acc: 0.5648\n",
      "Epoch 13/15\n",
      "5120/5120 [==============================] - 2s 415us/sample - loss: 0.7353 - acc: 0.6887 - val_loss: 0.6968 - val_acc: 0.6930\n",
      "Epoch 14/15\n",
      "5120/5120 [==============================] - 2s 432us/sample - loss: 0.6833 - acc: 0.7094 - val_loss: 0.6871 - val_acc: 0.7000\n",
      "Epoch 15/15\n",
      "5120/5120 [==============================] - 2s 435us/sample - loss: 0.6875 - acc: 0.7135 - val_loss: 0.7408 - val_acc: 0.6820\n",
      "Test loss: 0.7408416852355003\n",
      "Test accuracy: 0.6820313\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(X_flat_train.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(32, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=128,\n",
    "                          epochs=15,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classes=[0 1 2 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sm=SMOTE(random_state=42)\n",
    "\n",
    "train_data, train_labels = sm.fit_resample(X_flat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10260, 6075)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(-1, 45, 45, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10260, 6075)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 256)               1555456   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,650,564\n",
      "Trainable params: 1,650,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10260 samples, validate on 1280 samples\n",
      "Epoch 1/28\n",
      "10260/10260 [==============================] - 9s 880us/sample - loss: 1.0442 - acc: 0.4803 - val_loss: 0.8844 - val_acc: 0.5531\n",
      "Epoch 2/28\n",
      "10260/10260 [==============================] - 9s 873us/sample - loss: 0.7151 - acc: 0.6697 - val_loss: 0.8720 - val_acc: 0.5437\n",
      "Epoch 3/28\n",
      "10260/10260 [==============================] - 9s 887us/sample - loss: 0.5984 - acc: 0.7307 - val_loss: 0.7206 - val_acc: 0.6281\n",
      "Epoch 4/28\n",
      "10260/10260 [==============================] - 9s 905us/sample - loss: 0.5180 - acc: 0.7728 - val_loss: 0.7655 - val_acc: 0.6070\n",
      "Epoch 5/28\n",
      "10260/10260 [==============================] - 9s 901us/sample - loss: 0.4478 - acc: 0.8125 - val_loss: 2.4853 - val_acc: 0.4719\n",
      "Epoch 6/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.3971 - acc: 0.8382 - val_loss: 0.9059 - val_acc: 0.4945\n",
      "Epoch 7/28\n",
      "10260/10260 [==============================] - 10s 998us/sample - loss: 0.3548 - acc: 0.8558 - val_loss: 0.6128 - val_acc: 0.7352\n",
      "Epoch 8/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.3304 - acc: 0.8717 - val_loss: 1.7916 - val_acc: 0.5602\n",
      "Epoch 9/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.2815 - acc: 0.8916 - val_loss: 1.6290 - val_acc: 0.6820\n",
      "Epoch 10/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.2815 - acc: 0.9002 - val_loss: 0.3888 - val_acc: 0.8359\n",
      "Epoch 11/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.2347 - acc: 0.9163 - val_loss: 0.4948 - val_acc: 0.7914\n",
      "Epoch 12/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1943 - acc: 0.9328 - val_loss: 0.5330 - val_acc: 0.8031\n",
      "Epoch 13/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1807 - acc: 0.9375 - val_loss: 0.4075 - val_acc: 0.8523\n",
      "Epoch 14/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2261 - acc: 0.9429 - val_loss: 0.3298 - val_acc: 0.8687\n",
      "Epoch 15/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.1657 - acc: 0.9515 - val_loss: 0.3488 - val_acc: 0.8898\n",
      "Epoch 16/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1598 - acc: 0.9546 - val_loss: 0.3860 - val_acc: 0.8578\n",
      "Epoch 17/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.1964 - acc: 0.9565 - val_loss: 0.3953 - val_acc: 0.9117\n",
      "Epoch 18/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1921 - acc: 0.9575 - val_loss: 0.3017 - val_acc: 0.8977\n",
      "Epoch 19/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2050 - acc: 0.9624 - val_loss: 0.4178 - val_acc: 0.8680\n",
      "Epoch 20/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.1449 - acc: 0.9628 - val_loss: 0.2236 - val_acc: 0.9258\n",
      "Epoch 21/28\n",
      "10260/10260 [==============================] - 10s 992us/sample - loss: 0.8611 - acc: 0.9647 - val_loss: 0.3084 - val_acc: 0.9016\n",
      "Epoch 22/28\n",
      "10260/10260 [==============================] - 10s 1ms/sample - loss: 0.1448 - acc: 0.9655 - val_loss: 0.3515 - val_acc: 0.8977A: 1s - lo\n",
      "Epoch 23/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1288 - acc: 0.9711 - val_loss: 0.2786 - val_acc: 0.9102\n",
      "Epoch 24/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2525 - acc: 0.9701 - val_loss: 0.3523 - val_acc: 0.8859\n",
      "Epoch 25/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2016 - acc: 0.9690 - val_loss: 0.2151 - val_acc: 0.9297\n",
      "Epoch 26/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2175 - acc: 0.9726 - val_loss: 0.2237 - val_acc: 0.9398\n",
      "Epoch 27/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.2832 - acc: 0.9668 - val_loss: 0.2979 - val_acc: 0.8945\n",
      "Epoch 28/28\n",
      "10260/10260 [==============================] - 11s 1ms/sample - loss: 0.1521 - acc: 0.9716 - val_loss: 0.2039 - val_acc: 0.9406\n",
      "Test loss: 0.20389018105342985\n",
      "Test accuracy: 0.940625\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(train_data, train_labels,\n",
    "                          batch_size=32,\n",
    "                          epochs=28,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_deep.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_deep.save_weights(\"neural_network.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "alzheimers with cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
