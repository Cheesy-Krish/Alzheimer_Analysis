{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import ndimage\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LSTM, Input, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "import cv2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"oasis_longitudinal_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR2</td>\n",
       "      <td>Demented</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR3</td>\n",
       "      <td>Demented</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
       "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
       "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
       "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
       "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
       "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
       "\n",
       "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
       "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
       "4  NaN  22.0  0.5  1698  0.701  1.034  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
    "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Converted': 0, 'Demented': 1, 'Nondemented': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = np.array([label_to_id_dict[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 0, 0, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 1, 1,\n",
       "       1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 0, 0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 0,\n",
       "       0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(\"OAS2_RAW_PART1/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for file_path in files:\n",
    "    filename = os.path.join(file_path, 'RAW/mpr-1.nifti.img')\n",
    "    img = nib.load(filename)\n",
    "    image_data = img.get_fdata()\n",
    "    image=ndimage.rotate(image_data[:, :, 64,0],90)\n",
    "    ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "    c=pywt.wavedec2(thresh3[70:150,70:170],'db5',mode='periodization',level=2)\n",
    "    #image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "    cA2=c[0]\n",
    "    (cH1,cV1,cD1)=c[-1]\n",
    "    (cH2,cV2,cD2)=c[-2]\n",
    "    features.append(cD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(\"OAS2_RAW_PART2/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in files:\n",
    "    filename = os.path.join(file_path, 'RAW/mpr-1.nifti.img')\n",
    "    img = nib.load(filename)\n",
    "    image_data = img.get_fdata()\n",
    "    image=ndimage.rotate(image_data[:, :, 64,0],90)\n",
    "    ret, thresh3 = cv2.threshold(image, 120, 255, cv2.THRESH_TOZERO)\n",
    "    c=pywt.wavedec2(thresh3[70:150,70:170],'db5',mode='periodization',level=2)\n",
    "    #image = cv2.cvtColor(thresh3, cv2.COLOR_RGB2BGR)\n",
    "    cA2=c[0]\n",
    "    (cH1,cV1,cD1)=c[-1]\n",
    "    (cH2,cV2,cD2)=c[-2]\n",
    "    features.append(cD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features,label_ids, test_size = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 50)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize color values to between 0 and 1\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 4)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, 4)\n",
    "\n",
    "#Make a flattened version for some of our models\n",
    "#1st level feature extraction\n",
    "#X_flat_train = X_train.reshape(X_train.shape[0], 128*128*1)\n",
    "#X_flat_test = X_test.reshape(X_test.shape[0], 128*128*1)\n",
    "\n",
    "#2nd level feature extraction \n",
    "#X_flat_train = X_train.reshape(X_train.shape[0], 64*64*1)\n",
    "#X_flat_test = X_test.reshape(X_test.shape[0], 64*64*1)\n",
    "\n",
    "#Augmented level 2 feature extraction \n",
    "#X_flat_train = X_train.reshape(X_train.shape[0], 10*10*5)\n",
    "#X_flat_test = X_test.reshape(X_test.shape[0], 10*10*5)\n",
    "\n",
    "#Augmented level 1 feature extraction \n",
    "X_flat_train = X_train.reshape(X_train.shape[0], 20*20*5)\n",
    "X_flat_test = X_test.reshape(X_test.shape[0], 20*20*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_3d_train = X_train.reshape(X_train.shape[0], 64,64,1)\n",
    "#X_3d_test = X_test.reshape(X_test.shape[0], 64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_3d_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 2000)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=label_ids[:298]\n",
    "y_test=label_ids[298:373]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer model with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE(random_state=42)\n",
    "\n",
    "train_data, train_labels = sm.fit_resample(X_flat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 2000)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_294 (Dense)            (None, 512)               1024512   \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_247 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_248 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_249 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_250 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,217,859\n",
      "Trainable params: 1,217,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 298 samples, validate on 75 samples\n",
      "Epoch 1/10\n",
      "298/298 [==============================] - 3s 11ms/sample - loss: 1.0044 - acc: 0.4597 - val_loss: 0.8723 - val_acc: 0.5067\n",
      "Epoch 2/10\n",
      "298/298 [==============================] - 0s 973us/sample - loss: 0.7051 - acc: 0.7013 - val_loss: 0.9622 - val_acc: 0.4933\n",
      "Epoch 3/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.2107 - acc: 0.9228 - val_loss: 1.4006 - val_acc: 0.4933\n",
      "Epoch 4/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.0469 - acc: 0.9966 - val_loss: 1.9249 - val_acc: 0.5067\n",
      "Epoch 5/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.0142 - acc: 0.9966 - val_loss: 2.4812 - val_acc: 0.4933\n",
      "Epoch 6/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 2.6334 - val_acc: 0.4933\n",
      "Epoch 7/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 2.7581 - val_acc: 0.4933\n",
      "Epoch 8/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 3.0689 - val_acc: 0.4800\n",
      "Epoch 9/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 6.7556e-04 - acc: 1.0000 - val_loss: 3.3935 - val_acc: 0.4667\n",
      "Epoch 10/10\n",
      "298/298 [==============================] - 0s 1ms/sample - loss: 3.9650e-04 - acc: 1.0000 - val_loss: 3.6257 - val_acc: 0.4800\n",
      "Test loss: 3.625667584737142\n",
      "Test accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(512, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(256, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(X_flat_train, y_train,\n",
    "                          batch_size=32,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, \n",
    "                                           y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_263 (Dense)            (None, 256)               512256    \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 574,275\n",
      "Trainable params: 574,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 456 samples, validate on 75 samples\n",
      "Epoch 1/10\n",
      "456/456 [==============================] - 3s 6ms/sample - loss: 0.9175 - acc: 0.5482 - val_loss: 1.0178 - val_acc: 0.4400\n",
      "Epoch 2/10\n",
      "456/456 [==============================] - 0s 463us/sample - loss: 0.3387 - acc: 0.8947 - val_loss: 1.2877 - val_acc: 0.5333\n",
      "Epoch 3/10\n",
      "456/456 [==============================] - 0s 452us/sample - loss: 0.0460 - acc: 0.9956 - val_loss: 1.4505 - val_acc: 0.4933\n",
      "Epoch 4/10\n",
      "456/456 [==============================] - 0s 553us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 1.8310 - val_acc: 0.5200\n",
      "Epoch 5/10\n",
      "456/456 [==============================] - 0s 546us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 2.2101 - val_acc: 0.5067\n",
      "Epoch 6/10\n",
      "456/456 [==============================] - 0s 588us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 2.4287 - val_acc: 0.5200\n",
      "Epoch 7/10\n",
      "456/456 [==============================] - 0s 594us/sample - loss: 2.4105e-04 - acc: 1.0000 - val_loss: 3.5008 - val_acc: 0.4933\n",
      "Epoch 8/10\n",
      "456/456 [==============================] - 0s 493us/sample - loss: 9.9087e-05 - acc: 1.0000 - val_loss: 3.4819 - val_acc: 0.5200\n",
      "Epoch 9/10\n",
      "456/456 [==============================] - 0s 507us/sample - loss: 3.9521e-05 - acc: 1.0000 - val_loss: 3.5312 - val_acc: 0.4800\n",
      "Epoch 10/10\n",
      "456/456 [==============================] - 0s 774us/sample - loss: 2.2116e-05 - acc: 1.0000 - val_loss: 3.6929 - val_acc: 0.4800\n",
      "Test loss: 3.69290007909139\n",
      "Test accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "model_deep = Sequential()\n",
    "\n",
    "model_deep.add(Dense(256, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(128, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(64, activation='relu'))\n",
    "model_deep.add(Dropout(0.05))\n",
    "model_deep.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_deep.summary()\n",
    "\n",
    "model_deep.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_deep = model_deep.fit(train_data, train_labels,\n",
    "                          batch_size=32,\n",
    "                          epochs=10,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_flat_test, \n",
    "                                           y_test))\n",
    "score = model_deep.evaluate(X_flat_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
